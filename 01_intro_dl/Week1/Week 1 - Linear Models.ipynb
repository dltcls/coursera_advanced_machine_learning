{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning - Linar Models\n",
    "\n",
    "Linear Models:\n",
    "1. Building blocks for neural networks\n",
    "2. Supervised Learning:\n",
    "    - Labelled set of examples\n",
    "    - Ground truth for the given example\n",
    "    - Goal: Try to learn the function which better fits the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "1. $x_i$ = the given example\n",
    "2. $y_i$ = the corresponding label/target value\n",
    "3. $x_i = (x_{i1}, ... x_{id})$ = the features to learn from\n",
    "4. $X = ((x_1, y_1), ..., (x_l, y_l))$ = the training set with $l$ examples\n",
    "5. $a(x)$ = the model or the hypothesis\n",
    "\n",
    "### Goal\n",
    "\n",
    "$x -> a(x) -> y^{pred}$, where $a(x)$ can be a **regression** or a **classification** model.\n",
    "\n",
    "For a 1-class model: $y = w_1x + b$.\n",
    "\n",
    "For a multi-class model: $y = b + w_1x_1 + w_2x_2 + ... + w_dx_d$, where\n",
    "\n",
    "- $w_d$ are the model coefficients\n",
    "- $b$ is the bias term\n",
    "- $d+1$ is the number of parameters for the models (so number of features + bias term)\n",
    "\n",
    "In the vector notation the model can be described as: $a(x) = w^Tx$. And in the matrix notation: $a(X) = Xw$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality measure: Loss functions\n",
    "\n",
    "To measure the quality of a model, we need to measure how far the prediction goes from the real target value. To do this, loss functions are used.\n",
    "\n",
    "### Loss functions\n",
    "\n",
    "#### Mean Squared Error (MSE) Loss\n",
    "\n",
    "$L(w) =\\frac{1}{l}\\sum_{i=1}^{l} (w^Tx_i - y_i)^2$\n",
    "\n",
    "The goal is then to **minimize** the loss: $min(L(w))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Binary classification\n",
    "\n",
    "- $y \\in \\{-1,1\\})$\n",
    "- $a(x) = sign(w^Tx)$\n",
    "\n",
    "Number of parameters: $d$, $(w \\in R^d)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-class Classification\n",
    "\n",
    "- $y \\in \\{1,.., k\\})$, with $k$ as the number of classes\n",
    "- $a(x) = \\argmax w^T_kx\n",
    "\n",
    "Number of parameters: $d$, $(w \\in R^d)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss computation\n",
    "\n",
    "### Accuracy Loss\n",
    "\n",
    "- Ratio of how we correctly classified points\n",
    "\n",
    "$L(w) =\\frac{1}{l}\\sum_{i=1}^{l} a(x_i) = y_i$\n",
    "\n",
    "\n",
    "### Squared Loss\n",
    "\n",
    "- Consider $x_i$ such that $y_i = 1$\n",
    "\n",
    "$L(w) =\\frac{1}{l}\\sum_{i=1}^{l} (w^Tx_i -1)^2$\n",
    "\n",
    "- P is 1, if p is true\n",
    "- p is 0, if p is false\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "- Class scores (**logits**) from a linear model\n",
    "- How it works:\n",
    "    - $z = (w_1^Tx, ..., w_k^Tx)$, as scalar scores for each class\n",
    "    - Apply $e$ to each score: $(e^{z_1}, ...,e^{z_k})$\n",
    "    - Apply Sigmoid on the elements of this vector and normalize (**Softmax transform**): $\\sigma(z) = (\\frac{e^{z_1}}{\\sum_{k=1}^{K} e^{z_k}}\\frac{e^{z_k}}{\\sum_{k=1}^{K} e^^{z_k}}, ... ,\\frac{e^{z_k}}{\\sum_{k=1}^{K} e^{z_k}})$\n",
    "       - The softmax transform delivers a probability distribution over all classes!\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
